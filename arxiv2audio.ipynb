{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper to Audio\n",
    "\n",
    "This notebook will take in an HTML file of a paper and parse it into an audio book.\n",
    "TTS is generated through Kokoro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean text by removing non-ASCII characters and multiple spaces.\"\"\"\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def process_paragraph(p_tag) -> str:\n",
    "    \"\"\"Process a paragraph tag by removing unwanted elements and cleaning text.\"\"\"\n",
    "    # Remove math and cite tags\n",
    "    for tag in p_tag.find_all(['math', 'cite']):\n",
    "        tag.decompose()\n",
    "    \n",
    "    text = clean_text(p_tag.get_text(strip=False))\n",
    "    return text\n",
    "\n",
    "def process_abstract(soup) -> Dict[str, str]:\n",
    "    \"\"\"Extract and process the abstract section.\"\"\"\n",
    "    abstract = soup.find('div', class_='ltx_abstract')\n",
    "    if not abstract:\n",
    "        return None\n",
    "    \n",
    "    abstract_paras = []\n",
    "    for p in abstract.find_all('p', class_='ltx_p'):\n",
    "        text = process_paragraph(p)\n",
    "        if text:\n",
    "            abstract_paras.append(text)\n",
    "    \n",
    "    return {\n",
    "        \"title\": \"Abstract\",\n",
    "        \"content\": \"\\n\".join(abstract_paras)\n",
    "    }\n",
    "\n",
    "def process_section(section) -> Dict[str, str]:\n",
    "    \"\"\"Process a single section and return its title and content.\"\"\"\n",
    "    # Extract title\n",
    "    title_tag = section.find('h2', class_='ltx_title_section')\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"No Title\"\n",
    "    title = re.sub(r'^\\d+', '', title)\n",
    "    \n",
    "    # Process paragraphs\n",
    "    paragraphs = []\n",
    "    for p in section.find_all('p', class_='ltx_p'):\n",
    "        text = process_paragraph(p)\n",
    "        if text:\n",
    "            paragraphs.append(text)\n",
    "    \n",
    "    return {\n",
    "        \"title\": title.strip(),\n",
    "        \"content\": \"\\n\".join(paragraphs)\n",
    "    }\n",
    "\n",
    "def parse_paper_html(file_path_or_url: str, is_url: bool = False) -> List[Dict[str, str]]:\n",
    "    \"\"\"Main function to parse the paper HTML and return structured content.\"\"\"\n",
    "    # Read and parse HTML\n",
    "    if is_url:\n",
    "        import requests\n",
    "        html = requests.get(file_path_or_url).text\n",
    "    else:\n",
    "        with open(file_path_or_url, \"r\") as f:\n",
    "            html = f.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Initialize result list \n",
    "    section_list = []\n",
    "    \n",
    "    # Get HTML title\n",
    "    title_info = []\n",
    "    title_tag = soup.find('title')\n",
    "    if title_tag:\n",
    "        title_info.append({\n",
    "            \"title\": \"Title\",\n",
    "            \"content\": clean_text(title_tag.get_text())\n",
    "        })\n",
    "    \n",
    "    # Process abstract\n",
    "    abstract_section = process_abstract(soup)\n",
    "    if abstract_section:\n",
    "        section_list.append(abstract_section)\n",
    "    \n",
    "    # Process main sections\n",
    "    sections = soup.find_all('section', class_='ltx_section')\n",
    "    for section in sections:\n",
    "        section_data = process_section(section)\n",
    "        section_list.append(section_data)\n",
    "    \n",
    "    return section_list, title_info\n",
    "\n",
    "file_path = \"/home/iris/wsl_shared/paper_audio_book_generation/src_data/DeepSeek-V3 Technical Report.html\"\n",
    "section_list, title_info = parse_paper_html(file_path)\n",
    "\n",
    "# # Print sections for verification\n",
    "# for section in section_list:\n",
    "#     print(f\"\\n=== {section['title']} ===\")\n",
    "#     print(f\"Content length: {len(section['content'])} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_or_url = 'https://arxiv.org/html/2411.19799v1'\n",
    "section_list, title_info = parse_paper_html(file_path_or_url, is_url=True)\n",
    "\n",
    "# # Print sections for verification\n",
    "# for section in section_list:\n",
    "#     print(f\"\\n=== {section['title']} ===\")\n",
    "#     print(f\"Content length: {len(section['content'])} characters\")\n",
    "\n",
    "title_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_list[3][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kokoro.models import build_model\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL = build_model('kokoro/kokoro-v0_19.pth', device)\n",
    "VOICE_NAME = [\n",
    "    'af', # Default voice is a 50-50 mix of Bella & Sarah\n",
    "    'af_bella', 'af_sarah', 'am_adam', 'am_michael',\n",
    "    'bf_emma', 'bf_isabella', 'bm_george', 'bm_lewis',\n",
    "    'af_nicole', 'af_sky',\n",
    "][0]\n",
    "VOICEPACK = torch.load(f'kokoro/voices/{VOICE_NAME}.pt', weights_only=True).to(device)\n",
    "print(f'Loaded voice: {VOICE_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kokoro.kokoro import generate\n",
    "import nltk\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "# Download the punkt tokenizer if you haven't already\n",
    "nltk.download('punkt')\n",
    "\n",
    "def text_to_audio(text, model, voicepack, voice_name):\n",
    "    \"\"\"Generate audio for a single piece of text\"\"\"\n",
    "    audio, _ = generate(model, text, voicepack, lang=voice_name[0])\n",
    "    return audio\n",
    "\n",
    "def process_sections(section_list, model, voicepack, voice_name):\n",
    "    # Initialize empty list to store audio arrays\n",
    "    audio_segments = []\n",
    "    \n",
    "    for section in section_list:\n",
    "        print(f\"Procssing Section title: {section['title']}\")\n",
    "        # Generate audio for the title\n",
    "        title_audio = text_to_audio(section[\"title\"], model, voicepack, voice_name)\n",
    "        audio_segments.append(title_audio)\n",
    "        \n",
    "        # Add a short pause after the title\n",
    "        silence = np.zeros(12000)  # 1 second silence at 24kHz\n",
    "        audio_segments.append(silence)\n",
    "        \n",
    "        # Split content into sentences\n",
    "        sentences = nltk.sent_tokenize(section[\"content\"])\n",
    "        \n",
    "        # Generate audio for each sentence\n",
    "        for sentence in tqdm(sentences):\n",
    "            # print(sentence)\n",
    "            try:\n",
    "                sentence_audio = text_to_audio(sentence, model, voicepack, voice_name)\n",
    "            except:\n",
    "                # Split sentence by commas\n",
    "                parts = sentence.split(',')\n",
    "                parts = [part.strip() for part in parts if part.strip()]  # Remove empty parts and whitespace\n",
    "                \n",
    "                # Initialize array for combined audio\n",
    "                audio_parts = []\n",
    "                \n",
    "                # Process each part separately\n",
    "                for part in parts:\n",
    "                    part_audio = text_to_audio(part, model, voicepack, voice_name)\n",
    "                    audio_parts.append(part_audio)\n",
    "                \n",
    "                # Concatenate all parts\n",
    "                sentence_audio = np.concatenate(audio_parts)\n",
    "            audio_segments.append(sentence_audio)\n",
    "\n",
    "            \n",
    "            # Add a short pause between sentences\n",
    "            silence = np.zeros(12000)  # 0.5 second silence\n",
    "            audio_segments.append(silence)\n",
    "            \n",
    "        # Add a longer pause between sections\n",
    "        section_silence = np.zeros(24000)  # 2 seconds silence\n",
    "        audio_segments.append(section_silence)\n",
    "    \n",
    "    # Concatenate all audio segments\n",
    "    combined_audio = np.concatenate(audio_segments)\n",
    "    return combined_audio\n",
    "\n",
    "# Main execution\n",
    "def generate_audiobook(section_list, model, voicepack, voice_name, output_path):\n",
    "    # Process all sections and get combined audio\n",
    "    final_audio = process_sections(section_list, model, voicepack, voice_name)\n",
    "    \n",
    "    # Save as WAV file first\n",
    "    wav_path = output_path.replace('.mp3','.wav')\n",
    "    sf.write(wav_path, final_audio, 24000)\n",
    "    \n",
    "    # Convert to MP3 using pydub\n",
    "    from pydub import AudioSegment\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "    audio.export(output_path, format=\"mp3\")\n",
    "    \n",
    "    # Remove temporary WAV file\n",
    "    import os\n",
    "    os.remove(wav_path)\n",
    "    print(f\"Audio book has been saved to {output_path}\")\n",
    "    return final_audio\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Assuming you have MODEL, VOICEPACK, and VOICE_NAME defined as in your notebook\n",
    "output_file = \"audiobook2.mp3\"\n",
    "final_audio = generate_audiobook(section_list, MODEL, VOICEPACK, VOICE_NAME, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, Audio\n",
    "\n",
    "# display(Audio(data=final_audio, rate=24000, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to MP4 for YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "\n",
    "def create_image_with_text(text, width=1920, height=1080, font_path=\"DejaVuSans.ttf\"):\n",
    "    # Calculate dynamic font size (roughly 5% of image height)\n",
    "    font_size = int(height * 0.08)  # Adjust multiplier as needed\n",
    "    margin = int(width * 0.1)  # 10% margin of image width\n",
    "\n",
    "    # Load TrueType font with dynamic size\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_size = 12  # fallback size\n",
    "\n",
    "    # Create a new image with white background\n",
    "    image = Image.new('RGB', (width, height), 'white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate wrapping with new font size\n",
    "    max_width = width - 2 * margin\n",
    "    test_text = 'x' * 50\n",
    "    test_bbox = draw.textbbox((0, 0), test_text, font=font)\n",
    "    avg_char_width = test_bbox[2] / 50\n",
    "    chars_per_line = int((max_width) / avg_char_width)\n",
    "    wrapped_text = textwrap.fill(text, width=chars_per_line)\n",
    "\n",
    "    # Rest of your existing drawing code...\n",
    "    lines = wrapped_text.split('\\n')\n",
    "    line_height = font.getbbox('hg')[3]\n",
    "    total_text_height = line_height * len(lines)\n",
    "    start_y = (height - total_text_height) / 2\n",
    "\n",
    "    # Draw each line centered\n",
    "    for i, line in enumerate(lines):\n",
    "        line_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        line_width = line_bbox[2] - line_bbox[0]\n",
    "        x = (width - line_width) / 2\n",
    "        y = start_y + i * line_height\n",
    "        draw.text((x, y), line, font=font, fill='black')\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define the text\n",
    "text = title_info[0]['content']\n",
    "\n",
    "# Create the image\n",
    "image = create_image_with_text(text)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "title_text = title_info[0]['content']\n",
    "output_name = f\"{re.sub(r'[^a-zA-Z0-9]', '_', title_text)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip\n",
    "\n",
    "def create_image_clip(image, duration=5):\n",
    "    # Convert bytes to PIL Image\n",
    "    # image = Image.open(image)\n",
    "    # Convert PIL Image to ImageClip\n",
    "    clip = ImageClip(np.array(image)).set_duration(duration)\n",
    "    return clip\n",
    "\n",
    "title_clip = create_image_clip(image)\n",
    "\n",
    "\n",
    "# image_clip = ImageClip(\"src_data/DeepSeek-V3TechnicalReport.png\")\n",
    "audio_clip = AudioFileClip(f\"{output_name}.mp3\")\n",
    "video = title_clip.set_audio(audio_clip)\n",
    "video = video.set_duration(audio_clip.duration)\n",
    "video.write_videofile(f\"{output_name}.mp4\", fps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
